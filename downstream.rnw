%\VignetteIndexEntry{BeadArrayUseCases Vignette}
%\VignetteDepends{}
%\VignetteKeywords{Illumina Microarray Expression}
%\VignettePackage{BeadArrayUseCases}

\documentclass[a4paper,11pt]{article}

\textwidth=6.2in
\textheight=8.5in
\oddsidemargin=.1in
\evensidemargin=.1in
\headheight=-.3in
\parindent=0pt


\usepackage{amsthm,ragged2e,marvosym,wasysym}
\usepackage{mls40Sweave}
\usepackage[utf8]{inputenc}
\usepackage{sidecap}

\newcommand{\Rfunction}[1]{{\texttt{#1}}}
\newcommand{\Robject}[1]{{\texttt{#1}}}
\newcommand{\Rpackage}[1]{{\textsf{#1}}}
\newcommand{\Rmethod}[1]{{\texttt{#1}}}
\newcommand{\Rfunarg}[1]{{\texttt{#1}}}
\newcommand{\Rclass}[1]{{\textit{#1}}}

\SweaveOpts{eval=FALSE, keep.source=FALSE, results=hide}

\title{Further analysis of microarray data in Bioconductor}

\author{Mark Dunning}


\renewcommand\labelenumi{\textbf{Exercise \theenumi}}


% Sweave("IlluminaPLoSVignette.rnw")
\newtheoremstyle{labexc}%
{9pt}{12pt}%      space above and below
{\sffamily\RaggedRight}%              body style
{0pt}%       heading indent amount
{\sffamily\bfseries}{:}% heading font and punctuation after it
{ }%         space after heading is a new line
{}%          head spec (empty = same as 'plain' style)

\newtheoremstyle{myplain}%
{9pt}{9pt}%      space above and below
{\RaggedRight}%              body style
{0pt}%       heading indent amount
{\sffamily\bfseries}{}% heading font and punctuation after it
{ }%         space after heading is a new line
{}%          head spec (empty = same as 'plain' style)

\newtheoremstyle{mywarning}%
{9pt}{9pt}%      space above and below
{\itshape\RaggedRight}%              body style
{0pt}%       heading indent amount
{\sffamily\bfseries}{}% heading font and punctuation after it
{ }%         space after heading is a new line
{}%          head spec (empty = same as 'plain' style)

\theoremstyle{myplain} \newtheorem*{textinfo}{\large\Info}
\theoremstyle{labexc} \newtheorem*{exc}{Use Case}
\theoremstyle{mywarning} \newtheorem*{notebell}{\Large\bell}
\theoremstyle{myplain} \newtheorem*{noteright}{\Large\Pointinghand}
\theoremstyle{myplain} \newtheorem*{textstop}{\Large\Stopsign}
\theoremstyle{myplain} \newtheorem*{commentary}{\Large\CheckedBox}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}


\maketitle
\textinfo{Previously in this course, we have presented examples of how to pre-process gene-expression data generated on a specific platform (Illumina or Affymetrix) and produce a list of genes that show statistical evidence for differential expression. In most modern microarray experiments this is rarely the end-point of the analysis, and here we will introduce other ways that we can interrogate our gene expression data, which can be more open-ended or exploratory. The methods that we will apply rely on the data being stored in a common format such as the \Rclass{ExpressionSet} class using in Bioconductor. Hence, we can analyse any microarray technology using the same steps. Indeed, the data doesn't neccesarily need to be expression data. 

We will first show how pre-processed data may be obtained from the Gene Expression Omnibus and ArrayExpress repositories, and also from Bioconductor data packages.
}

<<setWidth, eval=TRUE, echo=FALSE>>=
options(width=70);
@

\section{Dealing with public data}
This section gives examples of how data can be imported into Bioconductor from the two most-popular data repositories, and via a pre-built Bioconductor pacakges. When importing such datasets, it is important to check the properties of the data to ensure that the distributional assumptions of our methods are valid, and that the appropriate sample meta data are available to allow comparisons to be made. 

\begin{itemize}
\item{Have the data normalized? If so, what method was used?}
\item{Has quality control been performed?}
\item{Is there sufficient sample meta-data to perform the analysis?}
\item{Are there any batch-effects remaining in the data?}
\end{itemize}

\subsection{Retrieving public data from GEO}

The data from this experiment comprises nine paired tumor/normal colon tissues on Illumina HT12\_v3 gene expression Beadchips. These data were generated to inform a comparison of technologies for microRNA profiling. However, we will only use the mRNA data here. 

\begin{exc}
Download the dataset with GEO GSE33126.
\end{exc}

<<>>=
library(GEOquery)
library(limma)
library(RColorBrewer)
url <- "ftp://ftp.ncbi.nih.gov/pub/geo/DATA/SeriesMatrix/GSE33126/"
filenm <- "GSE33126_series_matrix.txt.gz"
if(!file.exists("GSE33126_series_matrix.txt.gz")) download.file(paste(url, filenm, sep=""), destfile=filenm)
gse <- getGEO(filename=filenm)
@

We need to explore the data to ensure that they have been normalised and are on an appropriate scale for analysis.

\begin{exc}
Are the data on the log$_2$ scale? Are they normalised? Look at the phenotypic data stored with the object and find information about the sample groups in the study and patient IDs.
\end{exc}

<<>>=
head(exprs(gse))
exprs(gse) <- log2(exprs(gse))
boxplot(exprs(gse),outline=FALSE)
pData(gse)[1:2,]

SampleGroup <- pData(gse)$source_name_ch1
Patient <- pData(gse)$characteristics_ch1.1
@



\subsection{Downloading data from ArrayExpress}

\begin{exc}
Download the dataset E-TABM-25
\end{exc}

<<>>=
library(ArrayExpress)
ETABM25.affybatch = ArrayExpress("E-TABM-25")
ETABM25.affybatch 
@

<<>>=
print(ETABM25.affybatch)
sampleNames(ETABM25.affybatch)
colnames(pData(ETABM25.affybatch))
head(exprs(ETABM25.affybatch))
boxplot(log2(exprs(ETABM25.affybatch)),outline=FALSE)

@



\subsection{Using Bioconductor data packages}

The Bioconductor project has a collection of example datasets. Often these are used as examples to illustrate a particular package or functionality, or to accompany the analysis presented in a publication. The full list of datasets can be found here {\tt http://tinyurl.com/p5scw4a}

\begin{exc}
Install the {\tt breastCancerVDX} dataset
\end{exc}

<<>>=
source("http://www.bioconductor.org/biocLite.R")
biocLite("breastCancerVDX")
library(breastCancerVDX)
data(vdx)
pData(vdx)[1:4,]
head(exprs(vdx))
boxplot(exprs(vdx),outline=F)
@


\section{Clustering}

\subsection{Filtering the data}


A first step in the analysis of microarray data is often to remove any uniformative probes. We can do this because typically only 50$\%$ of probes genes will be expressed, and even fewer than this will be differentially expressed. Including such non-informative genes in visualisation will obscure any biological differences that exist with technical noise. The \Rpackage{genefilter} contains a suite of tools for the filtering of microarray data. 

<<genefilter>>=
library(genefilter)
filtData <- varFilter(gse)
dim(filtData)

@


\begin{exc}
Perform a hierarchical clustering on the filtered data  using Euclidean distance and average linkage agglomeration. Are there any distinct groups in the data? Try using the correlation based similarity measure and complete linkage. Does the choice of method effect your clustering?
\end{exc}

<<clustering>>=
par(mfrow=c(1,2))
clust.euclid = hclust(dist(t(exprs(filtData))), method = "complete")
clust.cor = hclust(as.dist(1 - cor(exprs(filtData))), method = "complete")


plot(clust.euclid,label = SampleGroup)
plot(clust.cor,label = SampleGroup)

@

\subsection{How many clusters are present?}


<<>>=
library(cluster)
cutree(clust.cor, k = 2)
cutree(clust.cor, h=0.12)
table(cutree(clust.cor, k = 2),SampleGroup)

@

<<>>=
for (k in 2:5) {
plot(silhouette(cutree(clust.cor, k = k), dist(t(exprs(filtData)))), col = "red", main = paste("k=", k))
}

@

\section{Principal Components Analysis and MDS}
Principal components analysis (PCA) is a data reduction technique that allows to simplify multidimensional data sets to 2 or 3 dimensions for plotting purposes and visual variance analysis.
\begin{exc}
Perform PCA
\end{exc}
<<PCA>>=
library(ggplot2)
distMat <- dist(t(exprs(filtData)))
pca <- prcomp(distMat)
summary(pca)


pcRes <- data.frame(pca$rotation,SampleGroup,Sample = rownames(pca$x),Patient)

ggplot(pcRes, aes(x=PC1,y=PC2,col=SampleGroup,label=Patient)) + geom_point() + geom_text(vjust=0,alpha=0.5)
ggplot(pcRes, aes(x=SampleGroup,y=PC1,fill=SampleGroup)) + geom_boxplot()
ggplot(pcRes, aes(x=SampleGroup,y=PC2,fill=SampleGroup)) + geom_boxplot()
@



\section{Producing a heatmap}

A heatmap is often used to visualise differences between samples. Each row represents a
gene and each column is an array and colours indicate the expression levels of genes. Both
samples and genes with similar expression profile are clustered together.
Drawing a heatmap in R uses a lot of memory and can take a long time, therefore reducing
the amount of data to be plotted is usually recommended. Typically, data are filtered to in-
clude the genes which tell us the most about the biological variation. Note that selection of
such genes is done without using prior knowledge about the samples.


\begin{exc}
Make a heatmap using the 100 most variable genes in the experiment according to
their inter-quartile range (IQR). Can you see any structure in the data?
\end{exc}
<<heatmap>>=
IQRs = apply(exprs(gse), 1, IQR)
highVarGenes = order(IQRs,decreasing=T)[1:100]
Symbols <- as.character(fData(gse)$Symbol[highVarGenes])
heatmap(as.matrix(exprs(gse)[highVarGenes, ]),ColSideColors=cols,labRow=Symbols,labCol=Patient)
@

The heatmap function can be customised in many ways to make the output more infor-
mative. For example, the labRow and labCol parameters can be used to give labels to the
rows (genes) and columns (arrays) of the heatmap. Similarly, ColSideColors and RowSide-
Colors give coloured labels, often used to indicate different groups which are know in ad-
vance. See the help page for heatmap for more details.

\section{Creating a classifer}

<<>>=
anov <- apply(exprs(nki), 1, function(x) t.test(x ~ pData(nki)$er)$p.value)

threshold <- quantile(anov, 3000/length(anov))

sub.Expression <- exprs(nki)[which(anov < threshold),]

naVals <- apply(sub.Expression , 1,function(x) any(is.na(x)))
sub.Expression <- sub.Expression[-which(naVals),]
library(class)

res <- knn(train = t(sub.Expression), test = t(sub.Expression),
cl = pData(nki)$er, k = 5)

er.ap <- table(res, pData(nki)$er)
er.ap <- 1 - sum(diag(er.ap))/sum(er.ap)
@




<<>>=
library(pamr)
dat <- exprs(vdx)
x<-NULL
x$x <- dat
dat <- pamr.knnimpute(x)$x
gN <- as.character(fData(vdx)$Gene.symbol)
gI <- featureNames(vdx)
sI <- sampleNames(vdx)

train.dat <- list(x = dat, y = pData(vdx)$er, genenames = gN, geneid = gI,sampleid = sI)
model <- pamr.train(train.dat, n.threshold = 100)
@


<<>>=

model.cv <- pamr.cv(model, train.dat, nfold = 10)
model.cv

pamr.plotcv(model.cv)
@


<<>>=
Delta <- 8
pamr.plotcen(model, train.dat, Delta)
pamr.confusion(model.cv, Delta)
pamr.plotcvprob(model, train.dat, Delta)
pamr.geneplot(model, train.dat, Delta)
@



<<>>=
source("http://www.bioconductor.org/biocLite.R")
biocLite("breastCancerMAINZ")
library(breastCancerMAINZ)
data(mainz)
pData(mainz)


table(pamr.predict(model, exprs(mainz), Delta), pData(mainz)$er)

boxplot(pamr.predict(model, exprs(mainz),Delta,type="posterior")[,1]~pData(mainz)$er)

@



\section{Survival Analysis}

<<>>=

plot(survfit(Surv(pData(vdx)$t.dmfs, pData(vdx)$e.dmfs) ~ pData(vdx)$er))
survdiff(Surv(pData(vdx)$t.dmfs, pData(vdx)$e.dmfs) ~ pData(vdx)$er)

library(genefu)
data(ssp2003)

intSubtype <- intrinsic.cluster.predict(sbt.model=ssp2003,data=t(exprs(vdx)), annot=fData(vdx), do.mapping=TRUE)$subtype
plot(survfit(Surv(pData(vdx)$t.dmfs, pData(vdx)$e.dmfs) ~ intSubtype))

@

\section{Gene-Ontology analysis}

\subsection{Non-specific filtering}
We are now going to create a gene universe by removing genes for will not contribute to
the subsequent analysis. Such filtering is done without regarding the phenotype variables -
hence a ”non-specific” filter.
The Illumina Human6 chip contains 47,293 probes, but less than half of these have enough
detailed information to useful for a GO analysis. Therefore we restrict the dataset to only
probes for which we have a Entrez ID.
It is also recommended to select probes with sufficient variability across samples to be inter-
esting; as probes with little variability will no be interesting to the question we are trying
to answer. The interquartile-range of each probe across all arrays is commonly used for this
with a cut-off of 0.5.

\begin{exc}
Create the gene universe of all genes with Entrez ID and with sufficient variation
across samples. How big is the universe?
\end{exc}

<<>>=
entrezIds = mget(rownames(exprs(gse)), illuminaHumanv3ENTREZID, ifnotfound = NA)
haveEntrezId = names(entrezIds)[sapply(entrezIds, function(x) !is.na(x))]
entrezSubset = exprs(gse)[haveEntrezId, ]
entrezIQR = apply(entrezSubset, 1, IQR)
selected = entrezIQR > 0.5
nsFiltered = entrezSubset[selected, ]
universeIds = unlist(mget(rownames(nsFiltered), illuminaHumanv3ENTREZID, ifnotfound = NA))
@

Remember that the size of the universe can have an effect on the analysis. If the universe
is made artificially large by including too many uninformative probes, the p-values for the
GO terms will appear more significant.


\subsection{Selecting genes of interest and performing Hypergeometric test}

We now test the genes in the universe to see which ones have significant differences be-
tween the two groups. For this, we use the rowttests function implemented in the GOstats
package, which performs a t-test for each row with respect to a factor. The p-values of the
test can be extracted, with one p-value given for each probe.

\begin{exc}
Do a t-test for each probe between the two groups of samples we have identified.
How many probes are significant at the 0.05 level? Define a list of genes to be used in the
hypergeometric test by finding the Entrez Ids for these significant probes.
\end{exc}

<<>>=
library(GOstats)
library(genefilter)
fac = as.factor(pData(gse)$source_name_ch1)
ttests = rowttests(as.matrix(nsFiltered), fac)
smPV = ttests$p.value < 0.05
pvalFiltered = nsFiltered[smPV, ]
dim(pvalFiltered)
selectedEntrezIds = unlist(mget(rownames(pvalFiltered), illuminaHumanv3ENTREZID, ifnotfound = NA))
@

The hyperGTest function is used to do the hypergeometric test for GO terms. Rather
than passing a long list of parameters to the function. An object of type GOHyperGParams
is created to hold all the parameters we need to run the hypergeometric test. This object
can then be passed to hyperGTest multiple times without having to re-type the parameters
each time.
The meanings of these parameters are as follows:
\begin{itemize}
\item geneIds - The list of identifiers for the genes that we have selected as interesting
\item universeGeneIds - The list of identifiers resulting from non-specific filtering
\item annotation - The name of the annotation package that will be used
\item ontology - The name of the GO ontology that will be tested; either BP, CC or MF
\item pvaluecutoff - p-value that we will use to select significant GO terms
\item testDirection - Either ”over” or ”under” for over or under represented terms respectively
\item conditional - A more sophisticated form of hypergeometric test, which takes the rela-
tionships between terms in the GO graph can be used if this is set to TRUE. For this
practical we will keep conditional = FALSE
\end{itemize}

\begin{exc}
Do a hypergeometric test to find which GO terms are over-represented in the
filtered list of genes. How many GO terms are significant with a p-value of 0.05?
\end{exc}

<<>>=
params = new("GOHyperGParams", geneIds = selectedEntrezIds, universeGeneIds = universeIds, annotation="illuminaHumanv3",ontology = "BP", pvalueCutoff = 0.05, conditional = FALSE, testDirection = "over")
hgOver = hyperGTest(params)
hgOver
@

The summary function can be used to view the results of the test in matrix form. The
rows of the matrix are arranged in order of significance. The p-value is shown for each GO
term along with with total number of genes for that GO term, number of genes we would be
expect to appear in the gene list by chance and that number that were observed. A descrip-
tive name is also given for each term. The results can also be printed out to a HTML report
using htmlReport.

\begin{exc}
View the results of the top 20 GO terms and create a HTML report.
\end{exc}
<<>>=
summary(hgOver)[1:20,]
@

GOstats also has the facility to test for KEGG pathways and chromosome bands which
are over-reprsented. The procedure of creating a gene universe and set of selected genes is
the same. However, we have to use a different object for the parameters, as not all 
\begin{exc}
Repeat the hypergeometric test for chromsome bands and KEGG pathways
\end{exc}
<<>>=
keggParams = new("KEGGHyperGParams", geneIds = selectedEntrezIds, universeGeneIds = universeIds,
annotation = "illuminaHumanv3", pvalueCutoff = 0.05, testDirection = "over")

keggHgOver = hyperGTest(keggParams)
summary(keggHgOver)


chrParams = new("ChrMapHyperGParams", geneIds = selectedEntrezIds, universeGeneIds = universeIds,annotation = "illuminaHumanv3", pvalueCutoff = 0.05, testDirection = "over",conditional = TRUE)
chrHgOver = hyperGTest(chrParams)
summary(chrHgOver)
@


\section{Appendix}



\subsection{Dealing with Batch Effects}

We will now see an example of a microarray dataset where additional processing is required before we can perform downstream analysis.

<<>>=
url <- "ftp://ftp.ncbi.nih.gov/pub/geo/DATA/SeriesMatrix/GSE5350/"
filenm <- "GSE5350-GPL2507_series_matrix.txt.gz"
download.file(paste(url, filenm, sep=""), destfile=filenm)
gse <- getGEO(filename=filenm)

dim(gse)
exprs(gse)[1:5,1:2]
 
samples <- as.character(pData(gse)[,"title"])
sites <- as.numeric(substr(samples,10,10))
shortlabels <- substr(samples,12,13)

rnasource <- pData(gse)[,"source_name_ch1"]
levels(rnasource) <- c("UHRR", "Brain", "UHRR75", "UHRR25")

d <- dist(t(exprs(gse)))
pc <- princomp(d)

boxplot(log2(exprs(gse)), col=sites+1, names=shortlabels, las=2, cex.names=0.5, ylab=expression(log[2](intensity)), outline=FALSE, ylim=c(3,10), main="Before batch correction")
@

<<>>=
gse.batchcorrect <- removeBatchEffect(log2(exprs(gse)), batch=sites)
boxplot(gse.batchcorrect, col=sites+1, names=shortlabels, las=2, cex.names=0.5, ylab=expression(log[2](intensity)), outline=FALSE, ylim=c(3,10), main="After batch correction")
d2 <- dist(t(gse.batchcorrect))
pc2 <- princomp(d2)

p2<-qplot(pc2$loadings[,1], pc2$loadings[,2],col=rnasource,pch=as.factor(Lab), main="With Correction")+xlab("PC1") + ylab("PC2")

@

<<>>=
library(sva)
mod <- model.matrix(~as.factor(rnasource))
gse.combat <- ComBat(exprs(gse), batch = sites, mod=mod,numCovs=NULL,par.prior=TRUE)
d2 <- dist(t(gse.combat))
pc2 <- princomp(d2)

p2<-qplot(pc2$loadings[,1], pc2$loadings[,2],col=rnasource,pch=as.factor(Lab), main="With Correction")+xlab("PC1") + ylab("PC2")

@


\end{document}
